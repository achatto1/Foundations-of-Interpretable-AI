<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Foundations of Interpretable AI</title>
  <meta name="description" content="Tutorial on Foundations of Interpretable AI." />
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<header class="sticky-header">
  <div class="header-banner">
    <img src="assets/images/header.png" alt="Interpretability in Deep Learning">
  </div>
  <nav>
    <strong>ICCV 2025 Tutorial</strong>
    <a href="#intro">Abstract</a>
    <a href="#schedule">Schedule</a>
    <a href="#organizers">Organizers</a>
  </nav>
</header>

<main>
  <h1>Foundations of Interpretable AI</h1>
  <p class="lead">Mon 20 Oct 8 a.m. — noon (HST). <span class="room">Room TBD</span></p>

  <section id="intro">
    <h2>Abstract</h2>
  <p>Interpretability has emerged as a key challenge for the widespread adoption of deep learning, especially in domains where AI decisions can profoundly affect human lives (e.g., healthcare, finance). This tutorial will
    provide an overview of two main approaches to interpretability along with a discussion of their respective strenghts and limitations:
    <ol>
        <li><strong>Post-hoc explainability:</strong> methods that explain existing models.</li>
        <li><strong>Explainable-by-design:</strong> methods that build inherently interpretable models.</li>
    </ol>
  </section>

  <section id="schedule">
    <h2>Schedule</h2>
    <table class="schedule">
      <tr><td class="time">08:00–08:15</td><td><strong>Opening remarks: Need for Interpretable AI</strong></td></tr>
      <tr><td class="time">8:15–9:00</td><td>Post-hoc explainability and explainable-by-design approachs to model interpretability<br/>
        <em>Aditya Chattopadhyay</em><br/>
        <a href="assets/slides/talk1.pdf">Slides</a>
      </td></tr>
      <tr><td class="time">9:00–9:15</td><td>Coffee Break</td></tr>
      <tr><td class="time">9:15–10:15</td><td>Shapley values based post-hoc explainability methods<br/>
        <em>Jeremias Sulam</em><br/>
        <a href="https://slides.com/jeremiassulam/cvpr2025/fullscreen">Slides</a>
      </td></tr>
      <tr><td class="time">10:15–10:30</td><td>Coffee Break</td></tr>
      <tr><td class="time">10:30–11:30</td><td>Information Pursuit: a framework for explainable-by-deisgn ML<br/>
        <em>René Vidal</em><br/>
        <a href="assets/slides/talk3.pdf">Slides</a>
      </td></tr>
      <tr><td class="time">11:30–noon</td><td>Q&A Session</td></tr>
    </table>
  </section>

  <section id="organizers">
    <h2>Organizers</h2>
    <ul>
      <li><a href="https://achatto1.github.io">Aditya Chattopadhyay</a> — AWS AI Labs </li>
      <li><a href="https://sites.google.com/view/jsulam">Jeremias Sulam</a> — Johns Hopkins University </li>
      <li><a href="http://vision.jhu.edu/rvidal.html">René Vidal</a> — University of Pennsylvania </li>
    </ul>
  </section>
</main>

<footer>
  © 2025 Your Lab. Hosted on GitHub Pages.
</footer>
</body>
</html>
